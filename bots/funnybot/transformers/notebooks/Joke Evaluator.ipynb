{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "130ecb82-dcfc-4abe-8ed6-ba78e8d14e29",
   "metadata": {},
   "source": [
    "# Funnybot's Evaluator Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook builds and evaluates models used by Funnybot to evaluate/rate jokes.\n",
    "\n",
    "I'm using the [GPT2 transformers](https://huggingface.co/gpt2) as well as other utilities from [Hugging Face](https://huggingface.co) to train and evaluate the models in this project.\n",
    "\n",
    "Due to my current hardware contraints and reluctance to spend some of my hard-earned money on cloud GPU's (in other words, I'm a cheapskate), this model does not work great, however, I hope that this notebook may be helpful to someone strugging to find a straigh-forward and complete tutorial on text classification on the web.\n",
    "\n",
    "The models from Hugging Face are basically pre-trained models that already have been optimized to have an understanding of natural language and classify natural language text. In this notebook we are going to fine-tune a model to classify text from a particular class, i.e., jokes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205e583-38b7-448c-b4cd-a0a5db93fb06",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21bc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import datetime\n",
    "\n",
    "import evaluate\n",
    "from evaluate import evaluator\n",
    "from evaluate import load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import profanity_check\n",
    "\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, GPT2Config, GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from transformers import TextClassificationPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dd60e-0dfb-43d8-8cf5-7d007ae2362a",
   "metadata": {},
   "source": [
    "This notebook requires the native dependencies from the \"Comedy Club\" project. You may install them by running:\n",
    "\n",
    "```\n",
    "cd <\"Comedy Club\" project root>\n",
    "pip install .\n",
    "```\n",
    "\n",
    "Additionally, the dependencies defined in [requirements.txt](../requirements-dev.txt) are required. You may install them by running:\n",
    "\n",
    "```\n",
    "pip install -r requirements-dev.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c784ff08-085a-45bb-a891-a24aa271e199",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "\n",
    "We are using the [Jester Dataset](https://www.kaggle.com/datasets/vikashrajluhaniwal/jester-17m-jokes-ratings-dataset). Not a very large dataset, which is to blame for the lack of performance of the result model.\n",
    "\n",
    "The dataset is actually split in two, one has the jokes themselves and the other the rates. The two datasets are related by an ID column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e26475-781a-4c55-974b-088b5ced2c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokeId</th>\n",
       "      <th>jokeText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A man visits the doctor. The doctor says \"I ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This couple had an excellent relationship goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth? \\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Q. What's the difference between a man and a t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>America: 8:00 - Welcome to work! 12:00 - Lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>It was the day of the big sale. Rumors of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>Recently a teacher, a garbage collector, and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>A little girl asked her father, \"Daddy? Do all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>In an interview with David Letterman, Carter p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jokeId                                           jokeText\n",
       "0         1  A man visits the doctor. The doctor says \"I ha...\n",
       "1         2  This couple had an excellent relationship goin...\n",
       "2         3  Q. What's 200 feet long and has 4 teeth? \\n\\nA...\n",
       "3         4  Q. What's the difference between a man and a t...\n",
       "4         5  Q.\\tWhat's O. J. Simpson's Internet address? \\...\n",
       "..      ...                                                ...\n",
       "145     146  America: 8:00 - Welcome to work! 12:00 - Lunch...\n",
       "146     147  It was the day of the big sale. Rumors of the ...\n",
       "147     148  Recently a teacher, a garbage collector, and a...\n",
       "148     149  A little girl asked her father, \"Daddy? Do all...\n",
       "149     150  In an interview with David Letterman, Carter p...\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path().absolute().parent.parent / \"data\"\n",
    "\n",
    "joke_ratings_items_df = pd.read_csv(data_dir / \"joke-ratings-items.csv\")\n",
    "\n",
    "joke_ratings_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a8f38a-87d1-436a-b857-52dc5d0b7ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>jokeId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761434</th>\n",
       "      <td>63978</td>\n",
       "      <td>57</td>\n",
       "      <td>-8.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761435</th>\n",
       "      <td>63978</td>\n",
       "      <td>24</td>\n",
       "      <td>-9.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761436</th>\n",
       "      <td>63978</td>\n",
       "      <td>124</td>\n",
       "      <td>-9.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761437</th>\n",
       "      <td>63978</td>\n",
       "      <td>58</td>\n",
       "      <td>-8.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761438</th>\n",
       "      <td>63978</td>\n",
       "      <td>44</td>\n",
       "      <td>-8.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1761439 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  jokeId  rating\n",
       "0             1       5   0.219\n",
       "1             1       7  -9.281\n",
       "2             1       8  -9.281\n",
       "3             1      13  -6.781\n",
       "4             1      15   0.875\n",
       "...         ...     ...     ...\n",
       "1761434   63978      57  -8.531\n",
       "1761435   63978      24  -9.062\n",
       "1761436   63978     124  -9.031\n",
       "1761437   63978      58  -8.656\n",
       "1761438   63978      44  -8.438\n",
       "\n",
       "[1761439 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings_values_df = pd.read_csv(data_dir / \"joke-ratings-values.csv\")\n",
    "\n",
    "joke_ratings_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4890ec7f-c2bf-4ffb-b54a-6ec048d8141d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n</td>\n",
       "      <td>-1.756331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n</td>\n",
       "      <td>-1.809230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n</td>\n",
       "      <td>-0.672010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n   \n",
       "1                       How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n   \n",
       "2              Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n   \n",
       "\n",
       "     labels  \n",
       "0 -1.756331  \n",
       "1 -1.809230  \n",
       "2 -0.672010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "joke_ratings_df = pd.merge(joke_ratings_items_df, joke_ratings_values_df, on=\"jokeId\")\n",
    "\n",
    "joke_ratings_df = joke_ratings_df.groupby([\"jokeId\", \"jokeText\"])[\"rating\"].mean().reset_index()\n",
    "joke_ratings_df = joke_ratings_df.rename(columns={\"jokeText\": \"text\", \"rating\": \"labels\"})\n",
    "joke_ratings_df = joke_ratings_df.drop(columns=[\"jokeId\"])\n",
    "\n",
    "joke_ratings_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aeb3c64",
   "metadata": {},
   "source": [
    "We are going to normalize our jokes just for the sake of being clerical, however, this doesn't seem to have a huge effect on the models performance.\n",
    "\n",
    "The following normalization will be applied to all jokes:\n",
    "\n",
    "- Remove non ASCII characters (with the assumption that jokes are always in English).\n",
    "- Remove some non-standard punctuation characters.\n",
    "- Remove excessive spacing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18153aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape.</td>\n",
       "      <td>-1.756331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many feminists does it take to screw in a light bulb? That's not funny.</td>\n",
       "      <td>-1.809230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.</td>\n",
       "      <td>-0.672010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            text  \\\n",
       "0  Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape.   \n",
       "1                    How many feminists does it take to screw in a light bulb? That's not funny.   \n",
       "2              Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.   \n",
       "\n",
       "     labels  \n",
       "0 -1.756331  \n",
       "1 -1.809230  \n",
       "2 -0.672010  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_sentence(row):\n",
    "    characters_to_remove = string.punctuation.replace(\".\", \"\").replace(\"-\", \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    text = row[\"text\"].encode('ascii', errors='ignore').decode()\n",
    "    text = \" \".join(text.split()).strip()\n",
    "    text = \" \".join(text.split(characters_to_remove)).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "joke_ratings_df[\"text\"] = joke_ratings_df.apply(normalize_sentence, axis=1)\n",
    "\n",
    "joke_ratings_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b078d4c-c276-41c0-8bba-9be8fe1176d4",
   "metadata": {},
   "source": [
    "As you may have noticed, the ratings are actualy float numbers and for our application we want rates as integers in the interval [1, 10]. For this reason, we are going to normalize these ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05627dd7-4860-4e55-888a-73d130533919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7495735330223425, 3.7143809194009174)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rating = joke_ratings_df[\"labels\"].max()\n",
    "min_rating = joke_ratings_df[\"labels\"].min()\n",
    "\n",
    "(min_rating, max_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67be8e7-38ef-447c-a732-2b99ebf04f22",
   "metadata": {},
   "source": [
    "Here we normalize the ratings. The models only work with labels in the interval [0, N]. This is because the tokenizer expects label ID's.\n",
    "\n",
    "Thus, given that we need 10 labels, our interval will be [0, 9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cdf1ff2-b97c-4445-a0b6-f87ba6150d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many feminists does it take to screw in a light bulb? That's not funny.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            text  \\\n",
       "0  Q. What's O. J. Simpson's Internet address? A. Slash, slash, backslash, slash, slash, escape.   \n",
       "1                    How many feminists does it take to screw in a light bulb? That's not funny.   \n",
       "2              Q. Did you hear about the dyslexic devil worshiper? A. He sold his soul to Santa.   \n",
       "\n",
       "   labels  \n",
       "0       1  \n",
       "1       1  \n",
       "2       3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rating = joke_ratings_df[\"labels\"].max()\n",
    "min_rating = joke_ratings_df[\"labels\"].min()\n",
    "\n",
    "max_target_rating = 9\n",
    "min_target_rating = 0\n",
    "\n",
    "\n",
    "def normalize_rating(row):\n",
    "    return round((row[\"labels\"] - min_rating) / (max_rating - min_rating) * (max_target_rating - min_target_rating) + min_target_rating)\n",
    "\n",
    "joke_ratings_df[\"labels\"] = joke_ratings_df.apply(normalize_rating, axis=1)\n",
    "\n",
    "joke_ratings_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea935a3f-ffa8-4606-ae5d-62712fba4a4a",
   "metadata": {},
   "source": [
    "Here we check our labels to see if they were normalized correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68a1ca7-4456-4f4b-a428-3bbe9c0f90dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.022535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           labels\n",
       "count  140.000000\n",
       "mean     6.100000\n",
       "std      2.022535\n",
       "min      0.000000\n",
       "25%      5.000000\n",
       "50%      6.500000\n",
       "75%      8.000000\n",
       "max      9.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48335c70-8a45-48f1-b3ba-2b9a1ccec430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(joke_ratings_df[\"labels\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a470c-b098-441b-bf27-0086858787e7",
   "metadata": {},
   "source": [
    "We want our model to output labels in the interval [1, 10], thus, we are required to create an ID to label mapping. This mapping will be use in the model's configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b363a9f-2a58-4e39-bac1-b3e99935ea67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {id:id + 1 for id in range(0, max_target_rating + min_target_rating + 1)}\n",
    "\n",
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae4940a-366e-406c-8c76-18539f2ff510",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "232e8283-fa11-4e2b-8c9b-b3a387467cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 42\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_ratings_df = joke_ratings_df.reset_index(drop=True)\n",
    "\n",
    "full_dataset = Dataset.from_pandas(joke_ratings_df)\n",
    "\n",
    "raw_datasets = full_dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d7c69",
   "metadata": {},
   "source": [
    "We no longer need the jokes dataframe, given that we have the raw dataset, thus, let's release some memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b65969f-24f0-4637-8f50-30fca7e600a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8629d468ad24efa9c197dc8ecd86615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"<|startoftext|>A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision. Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision. Americans: This is the Captain of a US Navy ship. I say again, divert YOUR course. Canadians: No. I say again, you divert YOUR course. Americans: This is the aircraft carrier USS LINCOLN, the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers, three cruisers and numerous support vessels. I demand that you change your course 15 degrees north, that's ONE FIVE DEGREES NORTH, or counter-measures will be undertaken to ensure the safety of this ship. Canadians: This is a lighthouse. Your call.<|endoftext|>\",\n",
       " '<|startoftext|>A man arrives at the gates of heaven. St. Peter asks, \"Religion?\" The man says, \"Methodist.\" St. Peter looks down his list, and says, \"Go to room 24, but be very quiet as you pass room 8.\" Another man arrives at the gates of heaven. \"Religion?\" \"Baptist.\" \"Go to room 18, but be very quiet as you pass room 8.\" A third man arrives at the gates. \"Religion?\" \"Jewish.\" \"Go to room 11, but be very quiet as you pass room 8.\" The man says, \"I can understand there being different rooms for different religions, but why must I be quiet when I pass room 8?\" St. Peter tells him, \"Well the Catholics are in room 8, and they think they\\'re the only ones here.<|endoftext|>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrap_text(example):\n",
    "    example[\"text\"] = \"<|startoftext|>\" + example[\"text\"] + \"<|endoftext|>\"\n",
    "    return example\n",
    "\n",
    "raw_datasets[\"train\"] = raw_datasets[\"train\"].map(wrap_text)\n",
    "\n",
    "raw_datasets[\"train\"][\"text\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a884750-47ee-40e6-8728-b294a0c33857",
   "metadata": {},
   "source": [
    "## Creating a Tokenizer\n",
    "\n",
    "As for the checkpoint, we are going to use [gpt2](https://huggingface.co/gpt2), which is suitable for text generation and small enough for the purposes of this challenge (development).\n",
    "\n",
    "Hugging Face makes available the following GPT2 checkpoints for transformers:\n",
    "\n",
    "- gpt2 (137M parameters)\n",
    "- gpt2-medium (380M parameters)\n",
    "- gpts-large (821M parameters)\n",
    "- gpt2-xl (1.5B parameters)\n",
    "\n",
    "Even gpt2-medium was challenging for my local computer, thus, we will stick to \"gpt2\" for the purposes of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd4083e-4502-4f0d-a10b-a23a97f1d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410dd979-f9f7-401b-96de-c6d8673353f3",
   "metadata": {},
   "source": [
    "The tokenizer we are going to use is the following (suitable for our classifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867e5d67-4eaf-41ab-a406-8db70b139a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|startoftext|>', 'This', 'Ä is', 'Ä my', 'Ä sentence', '.', '<|endoftext|>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    checkpoint, \n",
    "    bos_token=\"<|startoftext|>\", \n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    padding=True,\n",
    "    pad_token=\"<|pad|>\", \n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\"<|startoftext|>This is my sentence.<|endoftext|>\")\n",
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bd75c7-a683-4618-abc1-f76b65c35fb2",
   "metadata": {},
   "source": [
    ">***Note:***\n",
    ">\n",
    ">*The warning is just fine. We did add new tokens to the vocabulary (beggining/ending of sentence, and padding tokens) and we are going to fine-tune the word embeddings when we train the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27f7c884-2e89-48cb-b9c3-acf926aa76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803245595bcc442aa785a223f8d61811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/98 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8eca998d194b688bbac7c1af13dc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/42 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 98\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9edb606-6956-45fd-9a04-3300369079ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 42\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55b029-aa0f-4b85-bc4b-e2a014ecfcfd",
   "metadata": {},
   "source": [
    "The original feature columns can not be used for training, thus they will be removed. We also change the format to \"torch\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b51b7aca-12c0-4487-9bb7-9f0c557a6c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 98\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 42\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd1bc4d-bd47-445c-8169-68f42013303a",
   "metadata": {},
   "source": [
    "## Creating a Data Loader\n",
    "\n",
    "The data loader allows us to feed our dataset by batches during training. First we need to create a data collator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d94b35e2-9f18-468a-bb0d-93b0a1c95f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10653d99-c4d6-4d23-9c02-16379bd72049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([1]),\n",
       " 'input_ids': torch.Size([1, 111]),\n",
       " 'attention_mask': torch.Size([1, 111])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b846be6-cf4e-4910-8503-d7a3f759c401",
   "metadata": {},
   "source": [
    "## Training our Model\n",
    "\n",
    "Given that our purpose is text classification, [GPT2ForSequenceClassification](https://huggingface.co/docs/transformers/v4.15.0/model_doc/gpt2#transformers.GPT2ForSequenceClassification) is suitable for the job.\n",
    "\n",
    "The following might seem odd, but it's the [way recommended by Hugging Face](https://huggingface.co/docs/transformers/generation_strategies). We need to save a pre-trained model to temporary directory, modify its configuration, and then load the model from the temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5ef6fc1-daa0-4099-bdd6-fc8b3ab9f441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(14.5046, grad_fn=<NllLossBackward0>),\n",
       " tensor([[  1.4496, -10.4196,   0.4926,   4.2343,   2.1749, -10.0697,   5.5400,\n",
       "           -4.4224,  -7.0931,  10.0679]], grad_fn=<IndexBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config.from_pretrained(\n",
    "    checkpoint,\n",
    "    output_hidden_states=False,\n",
    "    num_labels=len(id2label),\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(checkpoint, config=configuration)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "outputs = model(**batch)\n",
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498f650-1b04-4f34-989c-1d6f08bbeda1",
   "metadata": {},
   "source": [
    ">***Note:***\n",
    ">\n",
    ">*The warning is just fine. Training the model is exactly what we intend to do.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fef954-d515-433f-a7de-01a4d5027eaf",
   "metadata": {},
   "source": [
    "Here are the parameters we will be using for our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e06b460-e800-452b-82fb-f413ae78c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 49)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "num_warmup_steps = int(num_training_steps * 0.1)\n",
    "\n",
    "(num_training_steps, num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1845e81-6237-4b0f-960f-38fa7285d815",
   "metadata": {},
   "source": [
    "To traing our model using [PyTorch](https://pytorch.org/) we will require the following components:\n",
    "\n",
    "- Optimizer (in case you are not familiar with ML, this optimizer implements stochastic gradient descent for neural networks).\n",
    "- Scheduler (a component that manages the iterations required to train the model).\n",
    "- Tokenizer (created in previous sections).\n",
    "- Data Loader (created in previous sections).\n",
    "\n",
    "We are going to use ADAM as our optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb50f3c-7827-4b33-a483-a909f085d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1edf13-a813-4cf5-abd5-7bad66db51e4",
   "metadata": {},
   "source": [
    "The device used depends on our own hardware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d256134f-b902-42d6-a727-eb077205e90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501993c-581f-4017-b22d-a3d0617b146b",
   "metadata": {},
   "source": [
    "Here's our scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36586edc-7f8d-4964-a76f-e3e7ca7374c9",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b817e2b4-3993-4968-bebf-cb8bf3e87168",
   "metadata": {},
   "source": [
    "Finally, we train our model using our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba5346b-c103-454d-bfcd-4d005f581a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451f973598e04d5c86ffdd5ca3cc8676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for _ in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae1024e-a6aa-480a-9605-1a1a1edf2327",
   "metadata": {},
   "source": [
    "## Testing our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6bb27f7-7d5c-40f8-adbd-541cd95c99fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>joke</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My dog has no nose. How does it smell? Awful!</td>\n",
       "      <td>[{'label': 10, 'score': 0.5223402380943298}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I can predict the motion of the heavenly bodies, but not the madness of people.</td>\n",
       "      <td>[{'label': 7, 'score': 0.45346590876579285}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acid rain. Drug addictions. International terrorism. Freeway killers.\\n       Now, more than ever, is important to remember the true meaning of Christmas.\\n       Don't miss Charles Dickens' immortal classic. \"Scrooge\".\\n       Your life might just depend on it.\\n</td>\n",
       "      <td>[{'label': 8, 'score': 0.2282678782939911}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always like walking in the rain, so no one can see me crying.</td>\n",
       "      <td>[{'label': 7, 'score': 0.45665329694747925}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                           joke  \\\n",
       "0                                                                                                                                                                                                                                 My dog has no nose. How does it smell? Awful!   \n",
       "1                                                                                                                                                                                               I can predict the motion of the heavenly bodies, but not the madness of people.   \n",
       "2  Acid rain. Drug addictions. International terrorism. Freeway killers.\\n       Now, more than ever, is important to remember the true meaning of Christmas.\\n       Don't miss Charles Dickens' immortal classic. \"Scrooge\".\\n       Your life might just depend on it.\\n       \n",
       "3                                                                                                                                                                                                               I always like walking in the rain, so no one can see me crying.   \n",
       "\n",
       "                                          label  \n",
       "0  [{'label': 10, 'score': 0.5223402380943298}]  \n",
       "1  [{'label': 7, 'score': 0.45346590876579285}]  \n",
       "2   [{'label': 8, 'score': 0.2282678782939911}]  \n",
       "3  [{'label': 7, 'score': 0.45665329694747925}]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = TextClassificationPipeline(\n",
    "    model=model.to(device),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "jokes = [\n",
    "    \"My dog has no nose. How does it smell? Awful!\",\n",
    "    \n",
    "    \"I can predict the motion of the heavenly bodies, but not the madness of people.\",\n",
    "\n",
    "    \"\"\"Acid rain. Drug addictions. International terrorism. Freeway killers.\n",
    "       Now, more than ever, is important to remember the true meaning of Christmas.\n",
    "       Don't miss Charles Dickens' immortal classic. \"Scrooge\".\n",
    "       Your life might just depend on it.\n",
    "    \"\"\",\n",
    "\n",
    "    \"I always like walking in the rain, so no one can see me crying.\",\n",
    "]\n",
    "    \n",
    "evaluator_results = [{\"joke\": joke, \"label\": pipe(joke)} for joke in jokes]\n",
    "\n",
    "pd.DataFrame(evaluator_results, index=[0] * len(jokes)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866c04a-20d0-4037-8ee0-fa44d82fdfa8",
   "metadata": {},
   "source": [
    "## Evaluating our Model\n",
    "\n",
    "We need to way to evaluate the performance of our models, thus we will use an evaluator. The evaluator requires an evaluation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32e952b3-6393-478a-851a-e71f56c7ae74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([1]),\n",
       " 'input_ids': torch.Size([1, 149]),\n",
       " 'attention_mask': torch.Size([1, 149])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b278bd-4969-4e3f-b86e-e62a0ab8de51",
   "metadata": {},
   "source": [
    "Here we generate the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "138124f2-6590-47fa-be87-cbad9bbd6925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.19047619047619047}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model.to(device)(**batch)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511874d1-38c0-4253-b810-b1975bf04299",
   "metadata": {},
   "source": [
    "Here are some results for different training parameters:\n",
    "\n",
    "| epochs| accuracy          |\n",
    "| ------| ----------------- |\n",
    "| 3     |0.23809523809523808|\n",
    "| 4     |0.09523809523809523|\n",
    "| 5     |0.16666666666666666|\n",
    "| 6     |0.11904761904761904|\n",
    "\n",
    "\n",
    "Not great results, but they can be improved with a larger GPT2 model and more data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337f0d1-90a6-41c5-ae18-528e845e6464",
   "metadata": {},
   "source": [
    "## Saving our Models\n",
    "### Local Environment\n",
    "\n",
    "We are required to save our models to the directory the application is expecting. The evaluator's model and tokenizer will be saved under the directory `./joke-evaluator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eda9fd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-evaluator/tokenizer/tokenizer_config.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-evaluator/tokenizer/special_tokens_map.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-evaluator/tokenizer/vocab.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-evaluator/tokenizer/merges.txt',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-evaluator/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = Path().absolute().parent / \"joke-evaluator\"\n",
    "\n",
    "model.save_pretrained(save_dir / \"model\")\n",
    "tokenizer.save_pretrained(save_dir / \"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82432065-e970-4a44-acb2-3c4133b34b90",
   "metadata": {},
   "source": [
    "### Hugging Face's Hub\n",
    "\n",
    "You will need a Hugging Face's acccount and of course you will only be able to push to repositories in your own account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5460ddee-f268-4c50-9ddd-e4dbd764d989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc4cf8bef214b42be741f9f4c6ebe3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/marciogualtieri/funnybot-joke-evaluator-tokenizer/commit/de871bc28abe811c2de46cf777d51bcfe5b374ea', commit_message='Upload tokenizer', commit_description='', oid='de871bc28abe811c2de46cf777d51bcfe5b374ea', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "model.push_to_hub(\"marciogualtieri/funnybot-joke-evaluator-model\")\n",
    "tokenizer.push_to_hub(\"marciogualtieri/funnybot-joke-evaluator-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4318dd75-fc75-4c73-b57b-d5b9820d97ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
