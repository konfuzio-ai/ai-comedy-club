{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4f1106-de29-4130-9bf4-4ed6cc52a931",
   "metadata": {},
   "source": [
    "# Funnybot's Generator Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook builds and evaluates models used by Funnybot to generate jokes. \n",
    "\n",
    "I'm using the [GPT2 transformers](https://huggingface.co/gpt2) as well as other utilities from [Hugging Face](https://huggingface.co) to train and evaluate the models in this project.\n",
    "\n",
    "Due to my current hardware contraints and reluctance to spend some of my hard-earned money on cloud GPU's (in other words, I'm a cheapskate), these models do not generate incredible jokes, however, I hope that these notebooks may be helpful to someone strugging to find a straigh-forward and complete tutorial on text generation on the web.\n",
    "\n",
    "The models from Hugging Face are basically pre-trained models that already have been optimized to have an understanding of natural language and generate natural language text. In this notebook we are going to fine-tune these models to generate text from a particular class, i.e., funny jokes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205e583-38b7-448c-b4cd-a0a5db93fb06",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ece742a-c239-459d-ad56-128a744bb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "import evaluate\n",
    "from evaluate import evaluator\n",
    "from evaluate import load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import profanity_check\n",
    "\n",
    "import string\n",
    "\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import PreTrainedTokenizer, DataCollatorWithPadding, GenerationConfig, TextGenerationPipeline\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, GPT2Tokenizer\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0dd60e-0dfb-43d8-8cf5-7d007ae2362a",
   "metadata": {},
   "source": [
    "This notebook requires the native dependencies from the \"Comedy Club\" project. You may install them by running:\n",
    "\n",
    "```\n",
    "cd <\"Comedy Club\" project root>\n",
    "pip install .\n",
    "```\n",
    "\n",
    "Additionally, the dependencies defined in [requirements.txt](../requirements-dev.txt) are required. You may install them by running:\n",
    "\n",
    "```\n",
    "pip install -r requirements-dev.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77dcb2-4804-4abe-99cc-870ec802fbe3",
   "metadata": {},
   "source": [
    "## Raw Data\n",
    "### Dad Jokes\n",
    "\n",
    "The following normalization will be applied to all jokes:\n",
    "\n",
    "- Remove non ASCII characters (with the assumption that jokes are always in English).\n",
    "- Remove some non-standard punctuation characters.\n",
    "- Remove excessive spacing.\n",
    "\n",
    "\n",
    "That's just to generate a nicer output for the application in our project. The GPT2 models don't seem to mind about those and I haven't notice any difference in the quality of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9afcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm tired of following my dreams. I'm just goi...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you hear about the guy whose whole left si...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why didnt the skeleton cross the road? Because...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What did one nut say as he chased another nut?...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where do fish keep their money? In the riverbank</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>What do you call a guy lying on your doorstep?...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>I met this girl on a dating site and, I don't ...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>What did the calculator say to the student? Yo...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>What do you call a gorilla wearing headphones?...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Have you heard about corduroy pillows? They're...</td>\n",
       "      <td>Dad Jokes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text       type\n",
       "0    I'm tired of following my dreams. I'm just goi...  Dad Jokes\n",
       "1    Did you hear about the guy whose whole left si...  Dad Jokes\n",
       "2    Why didnt the skeleton cross the road? Because...  Dad Jokes\n",
       "3    What did one nut say as he chased another nut?...  Dad Jokes\n",
       "4     Where do fish keep their money? In the riverbank  Dad Jokes\n",
       "..                                                 ...        ...\n",
       "738  What do you call a guy lying on your doorstep?...  Dad Jokes\n",
       "739  I met this girl on a dating site and, I don't ...  Dad Jokes\n",
       "740  What did the calculator say to the student? Yo...  Dad Jokes\n",
       "741  What do you call a gorilla wearing headphones?...  Dad Jokes\n",
       "742  Have you heard about corduroy pillows? They're...  Dad Jokes\n",
       "\n",
       "[743 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_sentence(row):\n",
    "    characters_to_remove = string.punctuation.replace(\".\", \"\").replace(\"-\", \"\").replace(\"'\", \"\")\n",
    "    \n",
    "    text = row[\"text\"].encode('ascii', errors='ignore').decode()\n",
    "    text = \" \".join(text.split()).strip()\n",
    "    text = \" \".join(text.split(characters_to_remove)).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "data_dir = save_dir = Path().absolute().parent.parent / \"data\"\n",
    "\n",
    "dad_jokes_df = pd.read_csv(data_dir / \"dad-jokes.csv\")\n",
    "dad_jokes_df[\"type\"] = \"Dad Jokes\"\n",
    "dad_jokes_df = dad_jokes_df.rename(columns={\"Joke\": \"text\"})\n",
    "\n",
    "dad_jokes_df[\"text\"] = dad_jokes_df.apply(normalize_sentence, axis=1)\n",
    "\n",
    "dad_jokes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841efeac-f2bd-41b6-b5cb-764c5fa364f3",
   "metadata": {},
   "source": [
    "Assuming that the jokes are always in the English language, I decided to encode the text to ASCII to remove non-standard punctuation characters from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87278917-3708-4779-b153-08ee662405b9",
   "metadata": {},
   "source": [
    "We will initialize our jokes dataset with \"Dad Jokes\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06866368",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = dad_jokes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cc17e-9a6d-479e-8257-d342c7ff0974",
   "metadata": {},
   "source": [
    "### Question/Answer Jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f862f8-fd38-4e02-be55-d64c09e9a0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32258</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>you met the short guy who came out of the cupb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16162</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>you know why Santa sack is so big? because he ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12611</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>you know who makes the best cocoa? paedophiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>you know what would be cool ? \" an ice cube .....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18938</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>you know what really turns on a nerd? unprotec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33029</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>\"What is your greatest strength\"? Brevity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21341</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>\"What do you call someone who makes cakes in S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>\"HUGE for an Asian\" slogan stupid or funny? Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>\"Did you hear about the $3,000,000 Maryland St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>Question Answer Jokes</td>\n",
       "      <td>\" What's the difference between snowmen and sn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        type  \\\n",
       "32258  Question Answer Jokes   \n",
       "16162  Question Answer Jokes   \n",
       "12611  Question Answer Jokes   \n",
       "2452   Question Answer Jokes   \n",
       "18938  Question Answer Jokes   \n",
       "...                      ...   \n",
       "33029  Question Answer Jokes   \n",
       "21341  Question Answer Jokes   \n",
       "14407  Question Answer Jokes   \n",
       "223    Question Answer Jokes   \n",
       "8431   Question Answer Jokes   \n",
       "\n",
       "                                                    text  \n",
       "32258  you met the short guy who came out of the cupb...  \n",
       "16162  you know why Santa sack is so big? because he ...  \n",
       "12611     you know who makes the best cocoa? paedophiles  \n",
       "2452   you know what would be cool ? \" an ice cube .....  \n",
       "18938  you know what really turns on a nerd? unprotec...  \n",
       "...                                                  ...  \n",
       "33029         \"What is your greatest strength\"? Brevity.  \n",
       "21341  \"What do you call someone who makes cakes in S...  \n",
       "14407  \"HUGE for an Asian\" slogan stupid or funny? Ye...  \n",
       "223    \"Did you hear about the $3,000,000 Maryland St...  \n",
       "8431   \" What's the difference between snowmen and sn...  \n",
       "\n",
       "[38269 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_question_and_answer(row):\n",
    "    return \" \".join([str(row[\"Question\"]).replace(\"Q:\", \"\"), str(row[\"Answer\"]).replace(\"A:\", \"\")])\n",
    "\n",
    "qa_jokes_df = pd.read_csv(data_dir / \"question-answer-jokes.csv\")\n",
    "qa_jokes_df[\"type\"] = \"Question Answer Jokes\"\n",
    "qa_jokes_df[\"text\"] = qa_jokes_df.apply(combine_question_and_answer, axis=1)\n",
    "qa_jokes_df[\"text\"] = qa_jokes_df.apply(normalize_sentence, axis=1)\n",
    "qa_jokes_df = qa_jokes_df.drop(columns=[\"ID\", \"Question\", \"Answer\"])\n",
    "\n",
    "qa_jokes_df.sort_values(\"text\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782343d0-6141-4073-a004-99f9ea3ed357",
   "metadata": {},
   "source": [
    "We now add the question/answer jokes to the jokes dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386f28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = pd.concat([qa_jokes_df, dad_jokes_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5484db25-9b40-4984-ae1d-bdb99096df34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question Answer Jokes', 'Dad Jokes']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types = jokes_df[\"type\"].unique().tolist()\n",
    "\n",
    "model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa546f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dad Jokes'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = model_types[1]\n",
    "\n",
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca4a6d3-2bff-41a9-9396-25cda0814e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I'm tired of following my dreams. I'm just goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Did you hear about the guy whose whole left si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Why didnt the skeleton cross the road? Because...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What did one nut say as he chased another nut?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Where do fish keep their money? In the riverbank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What do you call a guy lying on your doorstep?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I met this girl on a dating site and, I don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What did the calculator say to the student? Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What do you call a gorilla wearing headphones?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Have you heard about corduroy pillows? They're...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>743 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                                               text\n",
       "0    Dad Jokes  I'm tired of following my dreams. I'm just goi...\n",
       "1    Dad Jokes  Did you hear about the guy whose whole left si...\n",
       "2    Dad Jokes  Why didnt the skeleton cross the road? Because...\n",
       "3    Dad Jokes  What did one nut say as he chased another nut?...\n",
       "4    Dad Jokes   Where do fish keep their money? In the riverbank\n",
       "..         ...                                                ...\n",
       "738  Dad Jokes  What do you call a guy lying on your doorstep?...\n",
       "739  Dad Jokes  I met this girl on a dating site and, I don't ...\n",
       "740  Dad Jokes  What did the calculator say to the student? Yo...\n",
       "741  Dad Jokes  What do you call a gorilla wearing headphones?...\n",
       "742  Dad Jokes  Have you heard about corduroy pillows? They're...\n",
       "\n",
       "[743 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_df = jokes_df[jokes_df[\"type\"] == model_type]\n",
    "\n",
    "jokes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb4999e-7f10-4782-8cb9-4194068dd92b",
   "metadata": {},
   "source": [
    "The same process may be performed for any other specialty jokes category. We may a new type of joke to our dataset and create specific transformers for that dataset.\n",
    "\n",
    "We don't want any profanity in our dataset given that we are aiming for a \"clean\" bot, so we remove them from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef7c90a-95a2-4ecf-bb1b-5fb823d3cdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I'm tired of following my dreams. I'm just goi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Did you hear about the guy whose whole left si...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Why didnt the skeleton cross the road? Because...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Where do fish keep their money? In the riverbank</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I accidentally took my cats meds last night. D...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What do you call a guy lying on your doorstep?...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I met this girl on a dating site and, I don't ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What did the calculator say to the student? Yo...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>What do you call a gorilla wearing headphones?...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Have you heard about corduroy pillows? They're...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                                               text  profanity\n",
       "0    Dad Jokes  I'm tired of following my dreams. I'm just goi...      False\n",
       "1    Dad Jokes  Did you hear about the guy whose whole left si...      False\n",
       "2    Dad Jokes  Why didnt the skeleton cross the road? Because...      False\n",
       "3    Dad Jokes   Where do fish keep their money? In the riverbank      False\n",
       "4    Dad Jokes  I accidentally took my cats meds last night. D...      False\n",
       "..         ...                                                ...        ...\n",
       "725  Dad Jokes  What do you call a guy lying on your doorstep?...      False\n",
       "726  Dad Jokes  I met this girl on a dating site and, I don't ...      False\n",
       "727  Dad Jokes  What did the calculator say to the student? Yo...      False\n",
       "728  Dad Jokes  What do you call a gorilla wearing headphones?...      False\n",
       "729  Dad Jokes  Have you heard about corduroy pillows? They're...      False\n",
       "\n",
       "[730 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_profanity(row):\n",
    "    return profanity_check.predict([row[\"text\"]])[0] > 0\n",
    "\n",
    "jokes_df[\"profanity\"] = jokes_df.apply(check_profanity, axis=1)\n",
    "\n",
    "jokes_df.drop(jokes_df[jokes_df[\"profanity\"]].index, inplace = True)\n",
    "\n",
    "jokes_df = jokes_df.reset_index(drop=True)\n",
    "\n",
    "jokes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2af17-702c-4229-962b-dd3642ee46d7",
   "metadata": {},
   "source": [
    "This cell should be executed only for development purposes. It truncates the \"train\" dataset for a less time consuming training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe20420a-3efe-425d-b7a3-e2517d2f2733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I'm tired of following my dreams. I'm just goi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Did you hear about the guy whose whole left si...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Why didnt the skeleton cross the road? Because...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Where do fish keep their money? In the riverbank</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I accidentally took my cats meds last night. D...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>A man walked in to a bar with some asphalt on ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Did you know the first French fries weren't ac...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Ill tell you something about German sausages, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>Where did Captain Hook get his hook? From a se...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Dad Jokes</td>\n",
       "      <td>I got fired from a florist, apparently I took ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          type                                               text  profanity\n",
       "0    Dad Jokes  I'm tired of following my dreams. I'm just goi...      False\n",
       "1    Dad Jokes  Did you hear about the guy whose whole left si...      False\n",
       "2    Dad Jokes  Why didnt the skeleton cross the road? Because...      False\n",
       "3    Dad Jokes   Where do fish keep their money? In the riverbank      False\n",
       "4    Dad Jokes  I accidentally took my cats meds last night. D...      False\n",
       "..         ...                                                ...        ...\n",
       "495  Dad Jokes  A man walked in to a bar with some asphalt on ...      False\n",
       "496  Dad Jokes  Did you know the first French fries weren't ac...      False\n",
       "497  Dad Jokes  Ill tell you something about German sausages, ...      False\n",
       "498  Dad Jokes  Where did Captain Hook get his hook? From a se...      False\n",
       "499  Dad Jokes  I got fired from a florist, apparently I took ...      False\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "max_dataset_size = 500\n",
    "\n",
    "jokes_df = jokes_df[:max_dataset_size]\n",
    "\n",
    "jokes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257dc65-318a-45db-89f0-5ecce68eb96f",
   "metadata": {},
   "source": [
    "## Creating Datasets\n",
    "\n",
    "Now it's time to create datasets that can be consumed by the transformers. We will also split our dataset into two datasets, for training and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e423041-d441-4cdf-af1b-790492f86325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['type', 'text', 'profanity'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['type', 'text', 'profanity'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = Dataset.from_pandas(jokes_df)\n",
    "\n",
    "raw_datasets = full_dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721c85-a09a-4078-b458-f0697e52c0b4",
   "metadata": {},
   "source": [
    "We need to wrap every text with a start and end token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77362670-ac29-46e7-8bc8-1b2858a0e6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f40b765732c40c3a961c3bfa2cd291b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['<|startoftext|>I never wanted to believe that my Dad was stealing from his job as a road worker. But when I got home, all the signs were there.<|endoftext|>',\n",
       " '<|startoftext|>This furniture store keeps emailing me, all I wanted was one night stand!<|endoftext|>']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wrap_text(example):\n",
    "    example[\"text\"] = \"<|startoftext|>\" + example[\"text\"] + \"<|endoftext|>\"\n",
    "    return example\n",
    "\n",
    "raw_datasets[\"train\"] = raw_datasets[\"train\"].map(wrap_text)\n",
    "\n",
    "raw_datasets[\"train\"][\"text\"][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4fd8d1-84de-4b00-91e4-8fee835b816f",
   "metadata": {},
   "source": [
    "## Creating a Tokenizer\n",
    "\n",
    "As for the checkpoint, we are going to use [gpt2](https://huggingface.co/gpt2), which is suitable for text generation and small enough for the purposes of this challenge (development).\n",
    "\n",
    "Hugging Face makes available the following GPT2 checkpoints for transformers:\n",
    "\n",
    "- gpt2 (137M parameters)\n",
    "- gpt2-medium (380M parameters)\n",
    "- gpts-large (821M parameters)\n",
    "- gpt2-xl (1.5B parameters)\n",
    "\n",
    "Even gpt2-medium was challenging for my local computer, thus, we will stick to \"gpt2\" for the purposes of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c1df964-2d2f-4a63-ae1b-785e53897015",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2075b2a-6071-4f75-bd01-4b73e35e73dd",
   "metadata": {},
   "source": [
    "The tokenizer we are going to use is the following (suitable for our generator):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c3c34-cd9f-486f-9fdc-fe344540363e",
   "metadata": {},
   "source": [
    "Now we perform tokenization on our jokes dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d23fdb-d5a0-46f1-8666-abf18b555870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<|startoftext|>',\n",
       " 'This',\n",
       " 'Ġis',\n",
       " 'Ġmy',\n",
       " 'Ġsentence',\n",
       " '.',\n",
       " '<|endoftext|>',\n",
       " '<|pad|>']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\n",
    "    checkpoint,\n",
    "    bos_token=\"<|startoftext|>\",\n",
    "    eos_token=\"<|endoftext|>\",\n",
    "    padding=True,\n",
    "    pad_token=\"<|pad|>\",\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\"<|startoftext|>This is my sentence.<|endoftext|><|pad|>\")\n",
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af164f0d-7ebe-4424-9e61-e138d570cd9b",
   "metadata": {},
   "source": [
    ">***Note:***\n",
    ">\n",
    ">*The warning is just fine. We did add new tokens to the vocabulary (beggining/ending of sentence, and padding tokens) and we are going to fine-tune the word embeddings when we train the model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7cbf36a-cc79-424d-bd1a-85639dbc3901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ff9c464dc94d2f93fe036161382ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6935f35151b94ed0aa94c612d042712f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['type', 'text', 'profanity', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 350\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be2d406e-779f-43b4-bb67-e46f2376031b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['type', 'text', 'profanity', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 150\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2405a-3340-4768-8115-36b61cd65520",
   "metadata": {},
   "source": [
    "The original feature columns can not be used for training, thus they will be removed. We also change the format to \"torch\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b487aef-e3d7-4910-9e89-906e28efa85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", \"type\", \"profanity\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5089861-fdba-498c-bf1e-607cbf879eba",
   "metadata": {},
   "source": [
    "According to [this](https://discuss.huggingface.co/t/shifting-ids-to-the-right-when-training-gpt-2-on-text-generation/5308), labels should be initialized with the values of the input ID's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a933c99b-6f40-482c-a5c0-fb34cd890718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff35bfb604fe4d72829fe7c5da06b179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26227cbf3e042868b4003cc15326e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 350\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_labels(example):\n",
    "    example[\"labels\"] = example[\"input_ids\"]\n",
    "    return example\n",
    "\n",
    "tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].map(add_labels)\n",
    "tokenized_datasets[\"test\"] = tokenized_datasets[\"test\"].map(add_labels)\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8612c9e-e9cc-4842-b3ed-8d9a464fad6c",
   "metadata": {},
   "source": [
    "## Creating a Data Loader\n",
    "\n",
    "The data loader allows us to feed our dataset by batches during training. First we need to create a data collator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c607e60-8687-423d-8726-49024df868c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=GPT2Tokenizer(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=True), padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a35cb9-848c-4fcc-82e2-4e668f3ce614",
   "metadata": {},
   "source": [
    "Now we create a data loader for the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dfe9481-e1a5-40e8-80a4-05ef1d25cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([1, 17]),\n",
       " 'attention_mask': torch.Size([1, 17]),\n",
       " 'labels': torch.Size([1, 17])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd26ca4-aff2-4c36-b3d8-ef1fec320787",
   "metadata": {},
   "source": [
    "## Training our Model\n",
    "\n",
    "Given that our purpose is text generation, [GPT2LMHeadModel](https://huggingface.co/docs/transformers/v4.31.0/en/model_doc/gpt2#transformers.GPT2LMHeadModel) is suitable for the job.\n",
    "\n",
    "The following might seem odd, but it's the [way recommended by Hugging Face](https://huggingface.co/docs/transformers/generation_strategies). We need to save a pre-trained model to temporary directory, modify its configuration, and then load the model from the temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f1c3034-ebbe-42e3-a0c4-2d2210df42f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(77.5884, grad_fn=<NllLossBackward0>),\n",
       " tensor([[[ -36.9449,  -36.4698,  -40.5080,  ...,  -37.1380,   -1.3210,\n",
       "             -2.5912],\n",
       "          [ -99.8990, -100.1197, -103.9894,  ..., -101.4061,   -3.2685,\n",
       "             -7.5770],\n",
       "          [ -78.9669,  -78.4222,  -82.3988,  ...,  -79.1327,   -2.7331,\n",
       "             -6.0738],\n",
       "          ...,\n",
       "          [ -19.0832,  -18.6768,  -23.9441,  ...,  -21.0065,   -0.2918,\n",
       "             -0.8426],\n",
       "          [ -96.6570,  -95.2647,  -97.4394,  ...,  -93.1870,   -2.0474,\n",
       "             -6.7438],\n",
       "          [ -88.9241,  -81.9257,  -84.6400,  ...,  -90.6247,   -1.5910,\n",
       "             -5.8709]]], grad_fn=<UnsafeViewBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(checkpoint)\n",
    "temp_model_dir = \"/tmp/cached_gpt2_model\"\n",
    "shutil.rmtree(temp_model_dir, ignore_errors=True)\n",
    "model.save_pretrained(temp_model_dir)\n",
    "\n",
    "configuration = GenerationConfig(\n",
    "    max_new_tokens=100,\n",
    "    min_new_tokens=10,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    padding_side=tokenizer.padding_side\n",
    ")\n",
    "configuration.save_pretrained(temp_model_dir)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(temp_model_dir)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "outputs = model(**batch)\n",
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a8839-ba11-4bf7-82dc-4d5e8c5a08a0",
   "metadata": {},
   "source": [
    "To traing our model using [PyTorch](https://pytorch.org/) we will require the following components:\n",
    "\n",
    "- Optimizer (in case you are not familiar with ML, this optimizer implements stochastic gradient descent for neural networks).\n",
    "- Scheduler (a component that manages the iterations required to train the model).\n",
    "- Tokenizer (created in previous sections).\n",
    "- Data Loader (created in previous sections).\n",
    "\n",
    "We are going to use ADAM as our model's optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc98bdf1-dd5a-4587-8978-fa55905cdb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04398818-031b-42fa-b614-79a5ada5f3af",
   "metadata": {},
   "source": [
    "The device used depends on your own hardware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc0a865-7fec-4098-8f7d-27bb043a0ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd612d-d125-4d88-9992-47ed5a7d0fe2",
   "metadata": {},
   "source": [
    "Here are the parameters use for our training steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c7d2e4-20b3-4e8f-a816-a16283375869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 105)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "num_warmup_steps = int(num_training_steps * 0.1)\n",
    "\n",
    "(num_training_steps, num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d21fb-6db6-4ea1-8fed-75c676963de5",
   "metadata": {},
   "source": [
    "We will using 10% of our training steps for warm-up.\n",
    "\n",
    "Here's our scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f967d77c-dd89-4b9c-a4ce-1beb91455365",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b613e8c-d50e-4969-8a2d-30be3e4d7f65",
   "metadata": {},
   "source": [
    "Finally, we train our model using our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b72a23db-98c8-483d-ae91-7fe36d2c9a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8cdc94e7ab4cf1af15ef948ddf640d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model.to(device)(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76b343-caa7-4c8a-8216-fd302a500b64",
   "metadata": {},
   "source": [
    "> ***Note:***\n",
    "> \n",
    "> *If training is taking too long or you ran out of memory. Assuming that you are just running this notebook for the sake of learning, try to reduce `max_dataset_size` and `num_epochs`. These parameter variables have been defined earlier in this notebook. The performance of the models will degrade though.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fe3f4-f7d4-40d2-a92f-630cd3aefa8d",
   "metadata": {},
   "source": [
    "## Testing our Model\n",
    "\n",
    "Now we can create a pipeline that uses our model and tokenizer and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7824656f-91d4-42fd-a887-e65b23477859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"Why does the skylight make the sun look a little more blue? Because it can't make the moon look all that bad.\",\n",
       "  'I was afraid to open my fridge after I was told I was a vampire. I ate ice with the fridge. I have always been sad.'],\n",
       " 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = TextGenerationPipeline(\n",
    "    model=model.to(device),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "predictions = pipeline(\"\", num_return_sequences=len(raw_datasets[\"test\"]))\n",
    "predictions = [prediction[\"generated_text\"] for prediction in predictions]\n",
    "\n",
    "(predictions[:2], len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62140b46-1e56-414c-82c7-93a99075a7a1",
   "metadata": {},
   "source": [
    "## Evaluating our Model\n",
    "\n",
    "We need to way to evaluate the performance of our models, thus we will use an evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30f4cfc-2ff6-419b-bf82-8907a02bb86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   total_word_count |   unique_words |   total_time_in_seconds |   samples_per_second |   latency_in_seconds |\n",
      "|---:|-------------------:|---------------:|------------------------:|---------------------:|---------------------:|\n",
      "|  0 |               3691 |           1108 |                 68.9528 |               2.1754 |             0.459685 |\n"
     ]
    }
   ],
   "source": [
    "task_evaluator = evaluator(\"text-generation\")\n",
    "\n",
    "model.eval()\n",
    "evaluator_results = task_evaluator.compute(\n",
    "    model_or_pipeline=model.to(device),\n",
    "    tokenizer=tokenizer,\n",
    "    data=raw_datasets[\"test\"],\n",
    "    input_column=\"text\",\n",
    ")\n",
    "\n",
    "print(pd.DataFrame(evaluator_results, index=[0]).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42d8754-04e4-4be8-aea5-9377ee519e01",
   "metadata": {},
   "source": [
    "***epochs: 3***\n",
    "\n",
    "|    |   total_word_count |   unique_words |   total_time_in_seconds |   samples_per_second |   latency_in_seconds |\n",
    "|---:|-------------------:|---------------:|------------------------:|---------------------:|---------------------:|\n",
    "|  0 |               5068 |           1377 |                 148.925 |              1.47054 |             0.680024 |\n",
    "\n",
    "***epochs: 4***\n",
    "\n",
    "|    |   total_word_count |   unique_words |   total_time_in_seconds |   samples_per_second |   latency_in_seconds |\n",
    "|---:|-------------------:|---------------:|------------------------:|---------------------:|---------------------:|\n",
    "|  0 |               5105 |           1445 |                 170.742 |              1.28264 |             0.779644 |\n",
    "\n",
    "That's not extremely useful, so let's use the [BERT score](https://huggingface.co/spaces/evaluate-metric/bertscore) for evaluating text generation instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ae8fc3f-5095-41be-8e86-bc59821605f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>hashcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735906</td>\n",
       "      <td>0.752230</td>\n",
       "      <td>0.743979</td>\n",
       "      <td>distilbert-base-uncased_L5_no-idf_version=0.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.692580</td>\n",
       "      <td>0.682768</td>\n",
       "      <td>0.687639</td>\n",
       "      <td>distilbert-base-uncased_L5_no-idf_version=0.3....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1  \\\n",
       "0   0.735906  0.752230  0.743979   \n",
       "0   0.692580  0.682768  0.687639   \n",
       "\n",
       "                                            hashcode  \n",
       "0  distilbert-base-uncased_L5_no-idf_version=0.3....  \n",
       "0  distilbert-base-uncased_L5_no-idf_version=0.3....  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "references = raw_datasets[\"test\"][\"text\"]\n",
    "scorer_results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "scorer_results = pd.DataFrame(scorer_results, index=[0] * len(raw_datasets[\"test\"]))\n",
    "\n",
    "scorer_results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1041060-0ad4-43f7-97b2-cdd4f69e4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       |   precision |      recall |          f1 |\n",
      "|:------|------------:|------------:|------------:|\n",
      "| count | 150         | 150         | 150         |\n",
      "| mean  |   0.705332  |   0.701462  |   0.703114  |\n",
      "| std   |   0.0370431 |   0.0402527 |   0.0360881 |\n",
      "| min   |   0.611148  |   0.603059  |   0.615114  |\n",
      "| 25%   |   0.683321  |   0.675502  |   0.681355  |\n",
      "| 50%   |   0.702779  |   0.698414  |   0.701225  |\n",
      "| 75%   |   0.731247  |   0.72337   |   0.723633  |\n",
      "| max   |   0.800699  |   0.820124  |   0.801497  |\n"
     ]
    }
   ],
   "source": [
    "print(scorer_results.describe().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ced0e-b05e-48fb-ae5a-abcc751f7160",
   "metadata": {},
   "source": [
    "It can't tell if how funny a joke is, but at least it can compute the similarity between the jokes generated and a reference dataset (in our case, the \"test\" dataset).\n",
    "\n",
    "Here are some results for different training parameters:\n",
    "\n",
    "***epochs: 3 max_dataset_size: 700***\n",
    "\n",
    "|       |   precision |      recall |          f1 |\n",
    "|:------|------------:|------------:|------------:|\n",
    "| count | 219         | 219         | 219         |\n",
    "| mean  |   0.7054    |   0.70002   |   0.70246   |\n",
    "| std   |   0.0358243 |   0.0363763 |   0.0337329 |\n",
    "| min   |   0.592793  |   0.607776  |   0.600191  |\n",
    "| 25%   |   0.682816  |   0.673237  |   0.678634  |\n",
    "| 50%   |   0.702439  |   0.697652  |   0.700339  |\n",
    "| 75%   |   0.727483  |   0.724764  |   0.723261  |\n",
    "| max   |   0.828355  |   0.820289  |   0.802596  |\n",
    "\n",
    "***epochs: 4 max_dataset_size: 700***\n",
    "\n",
    "|       |   precision |      recall |          f1 |\n",
    "|:------|------------:|------------:|------------:|\n",
    "| count | 219         | 219         | 219         |\n",
    "| mean  |   0.705329  |   0.699855  |   0.702345  |\n",
    "| std   |   0.0428907 |   0.0411949 |   0.0399797 |\n",
    "| min   |   0.560061  |   0.595935  |   0.577442  |\n",
    "| 25%   |   0.675965  |   0.671475  |   0.674927  |\n",
    "| 50%   |   0.700021  |   0.695283  |   0.699969  |\n",
    "| 75%   |   0.728157  |   0.724505  |   0.723873  |\n",
    "| max   |   0.903992  |   0.891035  |   0.897467  |\n",
    "\n",
    "You may notice that there's no significant change in both precision and f1 scores increasing the number of epochs.\n",
    "\n",
    "The right procedure would be trying different parameters to squeeze as much performance as possible. However, it seems like we have reached already the threshold of overfitting.\n",
    "\n",
    "A larger dataset will improve performance, however, any AI model will eventually hit a performance threshold and not improve no matter how much data we use. AI models based on neural networks have a much higher threshold than any other, thus, we should expect to keep improving this model quite a bit by adding data.\n",
    "\n",
    "Being this project for demonstrating purposes, though I'm not willing to spent the time and resources to achieve peak performance.\n",
    "\n",
    "Using my current hardware (no GPU's, 8 MBytes of RAM), training this model with the full 38K records from \"Question Answer Jokes\" would take over 40 hours... Yep, I could use a computer upgrade (even though cloud GPU's probably would be a more cost effective alternative).\n",
    "\n",
    "Still, I probably do much more analysis and improve this notebook quite a lot, but I'll leave this for another weekend...\n",
    "\n",
    "***TODO:***\n",
    ">\n",
    ">- Sometimes that kernel will die due to out of memory. The notebook could use some memory optimization (i.e., deleting unused variables, using a context manager, strategically using Jupyter's reset command).\n",
    ">- Increase the dataset size even though it would take a good amount of hours to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61376451-932b-41a1-915d-77531bf2502c",
   "metadata": {},
   "source": [
    "## Saving our Models\n",
    "### Local Environment\n",
    "\n",
    "We are required to save our models to the directory the application is expecting.\n",
    "\n",
    "A new folder will be created for each different joke type. Models saved under `./joke-/models` will be used by our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5996ffbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-generator/tokenizer/tokenizer_config.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-generator/tokenizer/special_tokens_map.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-generator/tokenizer/vocab.json',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-generator/tokenizer/merges.txt',\n",
       " '/home/marcio/workspace/konfuzio-ai/ai-comedy-club/bots/funnybot/transformers/joke-generator/tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = Path().absolute().parent / \"joke-generator\"\n",
    "\n",
    "model.save_pretrained(save_dir / \"models\" / model_type)\n",
    "tokenizer.save_pretrained(save_dir / \"tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142e06e-ece4-4fac-8dbd-3918e3a06ce2",
   "metadata": {},
   "source": [
    "### Hugging Face's Hub\n",
    "\n",
    "You will need a Hugging Face's acccount and of course you will only be able to push to repositories in your own account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f56cf7-5f8a-4a62-a640-4cb8a1290f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6902cb9c585f43c2b4a52dda9b46228d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/marciogualtieri/funnybot-joke-generator-tokenizer/commit/0b5f6f3fab7922b1501dc05b35cc39cbe993ae39', commit_message='Upload tokenizer', commit_description='', oid='0b5f6f3fab7922b1501dc05b35cc39cbe993ae39', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "model.push_to_hub(f\"marciogualtieri/funnybot-joke-generator-model-{model_type.lower().replace(' ', '-')}\")\n",
    "tokenizer.push_to_hub(\"marciogualtieri/funnybot-joke-generator-tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
